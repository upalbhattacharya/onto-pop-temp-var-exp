{
    "input_file": "/storage/scratch/bhatt006/Projects/onto-pop-temp-var-exp/code/data/wines-ontology/most_common/2025-03-30/ontology_population_ranked_retrieval_dataset.json",
    "examples_file": "/storage/scratch/bhatt006/Projects/onto-pop-temp-var-exp/code/data/wines-ontology/most_common/2025-03-30/ontology_population_ranked_retrieval_examples.json",
    "output_dir": "/storage/scratch/bhatt006/Projects/onto-pop-temp-var-exp/code/results/llama3-8B/wines-ontology",
    "prompt_strategy_type": "3_shot",
    "llm_name": "meta-llama/Meta-Llama-3-8B-Instruct",
    "max_tokens": 1000,
    "temperature": 0.001,
    "load_in_8bit": false,
    "load_in_4bit": true,
    "device": 2,
    "trust_remote_code": true,
    "training_args": {
        "output_dir": "/storage/scratch/bhatt006/Projects/onto-pop-temp-var-exp/code/results/llama3-8B/wines-ontology",
        "overwrite_output_dir": false,
        "do_train": false,
        "do_eval": false,
        "do_predict": false,
        "eval_strategy": "no",
        "prediction_loss_only": false,
        "per_device_train_batch_size": 32,
        "per_device_eval_batch_size": 8,
        "per_gpu_train_batch_size": null,
        "per_gpu_eval_batch_size": null,
        "gradient_accumulation_steps": 1,
        "eval_accumulation_steps": null,
        "eval_delay": 0,
        "torch_empty_cache_steps": null,
        "learning_rate": 1e-05,
        "weight_decay": 0.0,
        "adam_beta1": 0.9,
        "adam_beta2": 0.999,
        "adam_epsilon": 1e-08,
        "max_grad_norm": 1.0,
        "num_train_epochs": 32.0,
        "max_steps": -1,
        "lr_scheduler_type": "linear",
        "lr_scheduler_kwargs": {},
        "warmup_ratio": 0.0,
        "warmup_steps": 0,
        "log_level": "passive",
        "log_level_replica": "warning",
        "log_on_each_node": true,
        "logging_dir": "/storage/scratch/bhatt006/Projects/onto-pop-temp-var-exp/code/results/llama3-8B/wines-ontology",
        "logging_strategy": "steps",
        "logging_first_step": false,
        "logging_steps": 500,
        "logging_nan_inf_filter": true,
        "save_strategy": "steps",
        "save_steps": 500,
        "save_total_limit": null,
        "save_safetensors": true,
        "save_on_each_node": false,
        "save_only_model": false,
        "restore_callback_states_from_checkpoint": false,
        "no_cuda": false,
        "use_cpu": false,
        "use_mps_device": false,
        "seed": 42,
        "data_seed": null,
        "jit_mode_eval": false,
        "use_ipex": false,
        "bf16": false,
        "fp16": false,
        "fp16_opt_level": "O1",
        "half_precision_backend": "auto",
        "bf16_full_eval": false,
        "fp16_full_eval": false,
        "tf32": null,
        "local_rank": 0,
        "ddp_backend": null,
        "tpu_num_cores": null,
        "tpu_metrics_debug": false,
        "debug": [],
        "dataloader_drop_last": false,
        "eval_steps": null,
        "dataloader_num_workers": 0,
        "dataloader_prefetch_factor": null,
        "past_index": -1,
        "run_name": null,
        "disable_tqdm": false,
        "remove_unused_columns": true,
        "label_names": null,
        "load_best_model_at_end": false,
        "metric_for_best_model": null,
        "greater_is_better": null,
        "ignore_data_skip": false,
        "fsdp": [],
        "fsdp_min_num_params": 0,
        "fsdp_config": {
            "min_num_params": 0,
            "xla": false,
            "xla_fsdp_v2": false,
            "xla_fsdp_grad_ckpt": false
        },
        "fsdp_transformer_layer_cls_to_wrap": null,
        "accelerator_config": {
            "split_batches": false,
            "dispatch_batches": null,
            "even_batches": true,
            "use_seedable_sampler": true,
            "non_blocking": false,
            "gradient_accumulation_kwargs": null,
            "use_configured_state": false
        },
        "deepspeed": null,
        "label_smoothing_factor": 0.0,
        "optim": "adamw_torch",
        "optim_args": null,
        "adafactor": false,
        "group_by_length": false,
        "length_column_name": "length",
        "report_to": [],
        "ddp_find_unused_parameters": null,
        "ddp_bucket_cap_mb": null,
        "ddp_broadcast_buffers": null,
        "dataloader_pin_memory": true,
        "dataloader_persistent_workers": false,
        "skip_memory_metrics": true,
        "use_legacy_prediction_loop": false,
        "push_to_hub": false,
        "resume_from_checkpoint": null,
        "hub_model_id": null,
        "hub_strategy": "every_save",
        "hub_token": null,
        "hub_private_repo": null,
        "hub_always_push": false,
        "hub_revision": null,
        "gradient_checkpointing": false,
        "gradient_checkpointing_kwargs": null,
        "include_inputs_for_metrics": false,
        "include_for_metrics": [],
        "eval_do_concat_batches": true,
        "fp16_backend": "auto",
        "push_to_hub_model_id": null,
        "push_to_hub_organization": null,
        "push_to_hub_token": null,
        "_n_gpu": 4,
        "mp_parameters": "",
        "auto_find_batch_size": false,
        "full_determinism": false,
        "torchdynamo": null,
        "ray_scope": "last",
        "ddp_timeout": 1800,
        "torch_compile": false,
        "torch_compile_backend": null,
        "torch_compile_mode": null,
        "include_tokens_per_second": false,
        "include_num_input_tokens_seen": false,
        "neftune_noise_alpha": null,
        "optim_target_modules": null,
        "batch_eval_metrics": false,
        "eval_on_start": false,
        "use_liger_kernel": false,
        "liger_kernel_config": null,
        "eval_use_gather_object": false,
        "average_tokens_across_devices": false
    },
    "system_message": "You are an ontology expert that responds with a ranked list of classes that a user input belongs to. Generate a list of the top {depth} most likely classes. Do not generate a list of less than {depth} classes. Do not provide any other information other than the list.\nCreate the ranked list considering only the provided classes\n---\nClasses: {classes}\nUse the following examples to generate responses for user inputs:\n {examples}",
    "user_prompt_template": "{}",
    "regex": null,
    "description": "3-Shot, Ontology Prompt, No pre-qualification Class Assertion Ranked Retrieval on Wines Ontology",
    "kwargs": {
        "depth": 4
    }
}